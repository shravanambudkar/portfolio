{"cells":[{"metadata":{"_uuid":"c2f303e138132ed3495fb122dd30141694da10df","_cell_guid":"81ebd5db-eb66-49f2-920d-75fbde680c95"},"cell_type":"markdown","source":"# I am predicting reviews for null values in dataset using already given reviews."},{"metadata":{"_uuid":"1fb38abd989c00734aafadb7290482db5484e067","_cell_guid":"3308441e-d2c1-4271-9e47-f9217a2a15f6","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"5fd2c5b476c3371905f898e0cf65b695ea9a7b4d","_cell_guid":"d2a5ef6c-143c-46c3-a7bb-802cc36269d4"},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"collapsed":true,"_uuid":"7bcd1e07ca092777802d58553fed4db595cf709c","_cell_guid":"e23115dc-bf4f-4f75-8eee-9ea94bdf9c38","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport nltk.classify.util\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.classify import NaiveBayesClassifier\nimport numpy as np\nimport re\nimport string\nimport nltk\n%matplotlib inline","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"118bb51d694e5ec0b4f34d96a135966dc4654bd4","_cell_guid":"ab3c2744-9bab-431e-a1df-32437a143e3d","trusted":true},"cell_type":"code","source":"temp = pd.read_csv(r\"../input/1429_1.csv\")\ntemp.head()","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"0f433f3faf598008d06f3aeb0898aec196abd6c7","_cell_guid":"d989623e-c622-45bd-8232-450f7c06ae01","trusted":true},"cell_type":"code","source":"permanent = temp[['reviews.rating' , 'reviews.text' , 'reviews.title' , 'reviews.username']]\nprint(permanent.isnull().sum()) #Checking for null values\npermanent.head()\n","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"5d9d31976e08c35ee092bba77f80aa9badbf35c3","_cell_guid":"fa18f4f5-020c-4676-9325-de8d39488570"},"cell_type":"markdown","source":"## Filtering null values"},{"metadata":{"_uuid":"f6d87f465ec602326168512617dfc72f69860e15","_cell_guid":"8d90d3f2-778f-4228-a950-aa3ed439a980","trusted":true},"cell_type":"code","source":"check =  permanent[permanent[\"reviews.rating\"].isnull()]\ncheck.head()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"e8a79c132dae52eba3fcad5935cb50f48820d3c5","_cell_guid":"4774bce2-b3fd-40b1-99b3-9589655fd61c"},"cell_type":"markdown","source":"## Filtering not null values"},{"metadata":{"_uuid":"0619937b511a032295187fe76b368adbca2a8c49","_cell_guid":"ef1db1ef-32c5-400a-8956-88bc33adc3c2","trusted":true},"cell_type":"code","source":"senti= permanent[permanent[\"reviews.rating\"].notnull()]\npermanent.head()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"d92a6d52db6097b71f35824c93342920026b4195","_cell_guid":"fb75db3a-585b-4de7-9607-c9f3035283f2"},"cell_type":"markdown","source":"## Classifying text as postive and negative"},{"metadata":{"_uuid":"3e73d8ce154f6e0ccaa7b712d8f05acc19b0d978","_cell_guid":"41696a53-19f1-4275-a5f9-8f2be0109afd","trusted":true},"cell_type":"code","source":"senti[\"senti\"] = senti[\"reviews.rating\"]>=4\nsenti[\"senti\"] = senti[\"senti\"].replace([True , False] , [\"pos\" , \"neg\"])","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"1c678f15281647e1acba8d5c2f5992933d058c0a","_cell_guid":"8f143c16-6ac1-45d2-ae1a-85906f21adb0"},"cell_type":"markdown","source":"## Count of reviews"},{"metadata":{"_uuid":"770aca195535cf73923aaef37bf24745ec54514e","_cell_guid":"89c5d3fc-3531-40a8-a0b8-1ab614fb6acd","trusted":true},"cell_type":"code","source":"senti[\"senti\"].value_counts().plot.bar()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"7ff0f235f0d8c4b80e6a603b0c264f91e606c3a9","_cell_guid":"8d6567c4-e499-4737-b91e-764b878d5730"},"cell_type":"markdown","source":"As we can see data is unbalanced so this will create problem for model but, will take this data as it is and will predict our reviews."},{"metadata":{"_uuid":"aaaf33172865ca5cc532c1c572b8cf1d07f9cd92","_cell_guid":"c56d24f3-eff5-45f5-910e-162a0b03c710"},"cell_type":"markdown","source":"## Cleaning text"},{"metadata":{"_uuid":"9ac6b57241511ac14d574531f7161ddcdb00cc8b","_cell_guid":"2fea4cdc-cb0b-4e01-9b67-3fc8471d1335","trusted":true},"cell_type":"code","source":"import nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nimport numpy as np\nimport re\nimport string\nimport nltk\n\ncleanup_re = re.compile('[^a-z]+')\ndef cleanup(sentence):\n    sentence = str(sentence)\n    sentence = sentence.lower()\n    sentence = cleanup_re.sub(' ', sentence).strip()\n    #sentence = \" \".join(nltk.word_tokenize(sentence))\n    return sentence\n\nsenti[\"Summary_Clean\"] = senti[\"reviews.text\"].apply(cleanup)\ncheck[\"Summary_Clean\"] = check[\"reviews.text\"].apply(cleanup)\n","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"c7e93168c642d5c091405ce85b0744de5c0ca354","_cell_guid":"a35ea44f-1edc-4730-9e5b-93e250a2ccfe"},"cell_type":"markdown","source":"## Splitting Train and Test Data"},{"metadata":{"_uuid":"f843f7a6c8731061183855b15a23a806754ce7a6","_cell_guid":"af7c6e3d-bdb5-4dbb-8e5d-99e1f869601d","trusted":true},"cell_type":"code","source":"split = senti[[\"Summary_Clean\" , \"senti\"]]\ntrain=split.sample(frac=0.8,random_state=200)\ntest=split.drop(train.index)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"27058ae188493485ca449bac9871de9437da3d05","_cell_guid":"7fbe6570-b5e9-4845-8a03-d2c67927581c"},"cell_type":"markdown","source":"## Feature Extracter for NLTK Naive bayes classifier"},{"metadata":{"collapsed":true,"_uuid":"5f2f34d01b7014bcdb9cd67133490fe8d48c9b76","_cell_guid":"8ed22181-6e32-4739-bb66-36a8428906d1","trusted":true},"cell_type":"code","source":"def word_feats(words):\n    features = {}\n    for word in words:\n        features [word] = True\n    return features\n","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"75d8848661e27e8d4dde26a15e971368be3c008f","_cell_guid":"8657105a-6d77-4765-8e54-6ef8ab1012ba","trusted":true},"cell_type":"code","source":"train[\"words\"] = train[\"Summary_Clean\"].str.lower().str.split()\ntest[\"words\"] = test[\"Summary_Clean\"].str.lower().str.split()\ncheck[\"words\"] = check[\"Summary_Clean\"].str.lower().str.split()\n\ntrain.index = range(train.shape[0])\ntest.index = range(test.shape[0])\ncheck.index = range(check.shape[0])\nprediction =  {} ## For storing results of different classifiers\n\ntrain_naive = []\ntest_naive = []\ncheck_naive = []\n\nfor i in range(train.shape[0]):\n    train_naive = train_naive +[[word_feats(train[\"words\"][i]) , train[\"senti\"][i]]]\nfor i in range(test.shape[0]):\n    test_naive = test_naive +[[word_feats(test[\"words\"][i]) , test[\"senti\"][i]]]\nfor i in range(check.shape[0]):\n    check_naive = check_naive +[word_feats(check[\"words\"][i])]\n\n\nclassifier = NaiveBayesClassifier.train(train_naive)\nprint(\"NLTK Naive bayes Accuracy : {}\".format(nltk.classify.util.accuracy(classifier , test_naive)))\nclassifier.show_most_informative_features(5)\n","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"ad1d1c3c4520884fe350be4a10e7992d792122fe","_cell_guid":"5ee3bb7e-55b8-408a-8aee-ef8f5123bf94"},"cell_type":"markdown","source":"## predicting result of nltk classifier"},{"metadata":{"_uuid":"2f7a02131c869647522aafeebc5ca18819621e18","_cell_guid":"aa113bf9-2b13-4fbb-9201-82ad8ee1d9e0","trusted":true},"cell_type":"code","source":"y =[]\nonly_words= [test_naive[i][0] for i in range(test.shape[0])]\nfor i in range(test.shape[0]):\n    y = y + [classifier.classify(only_words[i] )]\nprediction[\"Naive\"]= np.asarray(y)\n\ny1 = []\nfor i in range(check.shape[0]):\n    y1 = y1 + [classifier.classify(check_naive[i] )]\n\ncheck[\"Naive\"] = y1","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"739a8abfe26a70358ddb274cab0c3acb996e0a27","_cell_guid":"9358d370-3d07-4052-b9f7-68177915bf0c"},"cell_type":"markdown","source":"## Now we are bulding Countvector and Tfidf vector for train , test ,check data"},{"metadata":{"collapsed":true,"_uuid":"e278d75a576fed5542d677750f1b68ebbd947061","_cell_guid":"8f9f3477-896b-4de7-a70a-09724bd5b929","trusted":true},"cell_type":"code","source":"from wordcloud import STOPWORDS\n\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nstopwords = set(STOPWORDS)\nstopwords.remove(\"not\")\n\ncount_vect = CountVectorizer(min_df=2 ,stop_words=stopwords , ngram_range=(1,2))\ntfidf_transformer = TfidfTransformer()\n\nX_train_counts = count_vect.fit_transform(train[\"Summary_Clean\"])        \nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n\n\nX_new_counts = count_vect.transform(test[\"Summary_Clean\"])\nX_test_tfidf = tfidf_transformer.transform(X_new_counts)\n\ncheckcounts = count_vect.transform(check[\"Summary_Clean\"])\nchecktfidf = tfidf_transformer.transform(checkcounts)\n\n\n","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"2a55ae968bb538fed04ec512cfc76f46a2e76c9d","_cell_guid":"a72af24a-8afd-46c2-8a9b-c0f34e06a8c3"},"cell_type":"markdown","source":"## Fitiing Multinomial NB\n"},{"metadata":{"_uuid":"3240a0e0dc18bf3ed26e16846109145b815c5aac","_cell_guid":"4fbe128a-83ef-4cad-9161-e8e0bf4f0275","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel1 = MultinomialNB().fit(X_train_tfidf , train[\"senti\"])\nprediction['Multinomial'] = model1.predict_proba(X_test_tfidf)[:,1]\nprint(\"Multinomial Accuracy : {}\".format(model1.score(X_test_tfidf , test[\"senti\"])))\n\ncheck[\"multi\"] = model1.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"de97924ca8a7070fbae7f4e3cfee42917353f1be","_cell_guid":"830c637b-c970-4de0-8bc5-874afc9ce233"},"cell_type":"markdown","source":"## Fitiing Bernouli NB\n"},{"metadata":{"scrolled":true,"_uuid":"cc7784b7292590d9cc200bb274ea65785c40bca5","_cell_guid":"d6bf2247-112e-4e73-a5f0-5a9d436bceba","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nmodel2 = BernoulliNB().fit(X_train_tfidf,train[\"senti\"])\nprediction['Bernoulli'] = model2.predict_proba(X_test_tfidf)[:,1]\nprint(\"Bernoulli Accuracy : {}\".format(model2.score(X_test_tfidf , test[\"senti\"])))\n\ncheck[\"Bill\"] = model2.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"4e408529704d1472967dfd353432e5fc2dfa6015","_cell_guid":"2f1765a0-6300-47da-a3ae-5e6c54e4fa61"},"cell_type":"markdown","source":"## Fitiing LogisticRegression"},{"metadata":{"_uuid":"9fca90804b94b6191d3f8d7d13f9588ae9d8d346","_cell_guid":"b1ca2b0b-6dc3-4e4b-a604-598c40d2c35e","trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nlogreg = linear_model.LogisticRegression(solver='lbfgs' , C=1000)\nlogistic = logreg.fit(X_train_tfidf, train[\"senti\"])\nprediction['LogisticRegression'] = logreg.predict_proba(X_test_tfidf)[:,1]\nprint(\"Logistic Regression Accuracy : {}\".format(logreg.score(X_test_tfidf , test[\"senti\"])))\n\ncheck[\"log\"] = logreg.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"b5e5368e9a1ab45dde7f9809a744e42a732ce9ec","_cell_guid":"1f3789b6-eae3-4f66-a1b2-fe774db287cf"},"cell_type":"markdown","source":"## Getting most occuring words in train set\n"},{"metadata":{"scrolled":true,"_uuid":"1b184162bd29faf2e686ecce1dd9712a90705556","_cell_guid":"d935f7e8-f500-451b-a498-bae5ef5f1792","trusted":true},"cell_type":"code","source":"words = count_vect.get_feature_names()\nfeature_coefs = pd.DataFrame(\n    data = list(zip(words, logistic.coef_[0])),\n    columns = ['feature', 'coef'])\nfeature_coefs.sort_values(by=\"coef\")","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"8c68f174a9934d47bcc72aaf9cd66b3d522c8e8c","_cell_guid":"932b8a80-ddb8-491c-8a67-cc5171126de0"},"cell_type":"markdown","source":"## Lets find out which classifier is doing what"},{"metadata":{"_uuid":"bf7f6615a4d7b7d5226f9a0a75c40bb746fe7228","_cell_guid":"c4a865d3-37af-4dff-92fe-06c651364e2c","trusted":true},"cell_type":"code","source":"","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"c5d58f9f66cfea47cda26c53730bfa03b1ea6c3e","_cell_guid":"7f6519c1-8144-4e27-af7a-94fcf3010e37","trusted":true},"cell_type":"code","source":"def formatt(x):\n    if x == 'neg':\n        return 0\n    if x == 0:\n        return 0\n    return 1\nvfunc = np.vectorize(formatt)\n\ncmp = 0\ncolors = ['b', 'g', 'y', 'm', 'k']\nfor model, predicted in prediction.items():\n    if model not in 'Naive':\n        false_positive_rate, true_positive_rate, thresholds = roc_curve(test[\"senti\"].map(vfunc), predicted)\n        roc_auc = auc(false_positive_rate, true_positive_rate)\n        plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n        cmp += 1\n\nplt.title('Classifiers comparaison with ROC')\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"6c732f04807cc36e931ba54a0f5de7af3039d615","_cell_guid":"3a0e832c-ac72-4bb4-abee-6ea1c057b554"},"cell_type":"markdown","source":"## Lets see precision  and recall  of  different  classifiers\n"},{"metadata":{"_uuid":"8a6d626be55be9763aeec43881cb0e99268e3664","_cell_guid":"685fabad-8cc6-4823-82db-5b85d41e6b07"},"cell_type":"markdown","source":"![Precision_Recall](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a38640a5eebd3445966c6302de2fa5f7db45a560"},"cell_type":"code","source":"test.senti = test.senti.replace([\"pos\" , \"neg\"] , [True , False] )","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"cd8b8d9474933bd0ec03a112caaf40d3118c15a8","_cell_guid":"1aef6c14-a525-4880-992a-9de2d5d51987","trusted":true,"scrolled":true},"cell_type":"code","source":"keys = prediction.keys()\nfor key in ['Multinomial', 'Bernoulli', 'LogisticRegression']:\n    print(\" {}:\".format(key))\n    print(metrics.classification_report(test[\"senti\"], prediction.get(key)>.5, target_names = [\"positive\", \"negative\"]))\n    print(\"\\n\")","execution_count":55,"outputs":[]},{"metadata":{"_uuid":"57ccfe020ea6bd0f999026a24aae722e5aee0905","_cell_guid":"b6e0a360-0679-4a9c-b926-b62d29711dec"},"cell_type":"markdown","source":"## Let test our classifiers with some handwritten samples\n"},{"metadata":{"_uuid":"b50248fed62b75959a19a020e3bdbe1816a801aa","_cell_guid":"b7c724c3-8371-4668-8c7a-e1647389b4e3","trusted":true},"cell_type":"code","source":"def test_sample(model, sample):\n    sample_counts = count_vect.transform([sample])\n    sample_tfidf = tfidf_transformer.transform(sample_counts)\n    result = model.predict(sample_tfidf)[0]\n    prob = model.predict_proba(sample_tfidf)[0]\n    print(\"Sample estimated as %s: negative prob %f, positive prob %f\" % (result.upper(), prob[0], prob[1]))\n\ntest_sample(logreg, \"The product was good and easy to  use\")\ntest_sample(logreg, \"the whole experience was horrible and product is worst\")\ntest_sample(logreg, \"product is not good\")\n","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"e20eac56a0fc3f288bc5da068ce8cb304118ea62","_cell_guid":"a308cc57-0854-4399-916f-53f3b77b1931"},"cell_type":"markdown","source":"## Here is predicted valuesof classifiers for check on the basis of review text"},{"metadata":{"_uuid":"5b6b4a8a622fc316bd90020b00e4b5a9174bd249","_cell_guid":"8cbeb076-c8e9-4ade-b3a6-a7fe840c5b6c","trusted":true},"cell_type":"code","source":"check.head(10)\n\n","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"b73de1dc5f6866c5b9e4f6717c5ca8b3bba3930f","_cell_guid":"40e0b5a2-02e2-4f87-a0a0-b9c159363171","trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\n\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=300,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n        \n    ).generate(str(data))\n    \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \nshow_wordcloud(senti[\"Summary_Clean\"])\n","execution_count":43,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"94dd43ba61c11b6c7b13663d49b20b2153ef05c3","_cell_guid":"06904773-5d5a-42c2-b1ef-b090640de2c2","trusted":false},"cell_type":"code","source":"show_wordcloud(senti[\"Summary_Clean\"][senti.senti == \"pos\"] , title=\"Postive Words\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"b748fdc88a520b5e9989349efe24b2ce572e71e0","_cell_guid":"4fa3c881-b7ef-41ac-ad8d-52f221cf7315","trusted":false},"cell_type":"code","source":"show_wordcloud(senti[\"Summary_Clean\"][senti.senti == \"neg\"] , title=\"Negitive words\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"723db44c7421c6d08229b1e53dcfb4db4fe32090","_cell_guid":"01146775-1a28-428e-9351-9e8a6cf03b98","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}